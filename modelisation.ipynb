{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-20T10:04:35.618928700Z",
     "start_time": "2023-12-20T10:04:35.584659300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "      county  is_business  product_type   target  is_consumption  \\\n0         14            1             3  180.511               0   \n1          7            0             1   43.490               1   \n2         10            0             1    1.823               0   \n3          9            1             1   61.196               1   \n4          1            0             3  214.931               0   \n...      ...          ...           ...      ...             ...   \n9995       5            1             1  168.353               0   \n9996       5            1             0   40.860               1   \n9997       9            0             1   22.459               1   \n9998       2            1             1   37.480               1   \n9999      10            1             3  832.065               1   \n\n      data_block_id   row_id  prediction_unit_id  euros_per_mwh  \\\n0                16    48790                  56         110.09   \n1                51   153919                  25         154.89   \n2                69   207746                  38          65.09   \n3               123   371717                  36         117.64   \n4               251   778486                   7         183.91   \n...             ...      ...                 ...            ...   \n9995            591  1870136                  22          70.36   \n9996            325  1014639                  21         145.66   \n9997            367  1149565                  34         204.12   \n9998            341  1065697                  65         382.92   \n9999             80   240765                  42         116.12   \n\n      lowest_price_per_mwh  highest_price_per_mwh  year  month  day  hour  \n0                    47.09                  48.62  2021      9   17    15  \n1                    67.01                  68.78  2021     10   22    20  \n2                    65.00                  75.99  2021     11    9    15  \n3                    75.00                  90.00  2022      1    2    19  \n4                    98.00                 104.12  2022      5   10     9  \n...                    ...                    ...   ...    ...  ...   ...  \n9995                 46.50                  60.00  2023      4   15    10  \n9996                159.74                 200.00  2022      7   23     3  \n9997                219.99                 235.98  2022      9    3    16  \n9998                184.00                 207.00  2022      8    8     6  \n9999                 80.00                  85.00  2021     11   20    13  \n\n[10000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>county</th>\n      <th>is_business</th>\n      <th>product_type</th>\n      <th>target</th>\n      <th>is_consumption</th>\n      <th>data_block_id</th>\n      <th>row_id</th>\n      <th>prediction_unit_id</th>\n      <th>euros_per_mwh</th>\n      <th>lowest_price_per_mwh</th>\n      <th>highest_price_per_mwh</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>1</td>\n      <td>3</td>\n      <td>180.511</td>\n      <td>0</td>\n      <td>16</td>\n      <td>48790</td>\n      <td>56</td>\n      <td>110.09</td>\n      <td>47.09</td>\n      <td>48.62</td>\n      <td>2021</td>\n      <td>9</td>\n      <td>17</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>43.490</td>\n      <td>1</td>\n      <td>51</td>\n      <td>153919</td>\n      <td>25</td>\n      <td>154.89</td>\n      <td>67.01</td>\n      <td>68.78</td>\n      <td>2021</td>\n      <td>10</td>\n      <td>22</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.823</td>\n      <td>0</td>\n      <td>69</td>\n      <td>207746</td>\n      <td>38</td>\n      <td>65.09</td>\n      <td>65.00</td>\n      <td>75.99</td>\n      <td>2021</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>61.196</td>\n      <td>1</td>\n      <td>123</td>\n      <td>371717</td>\n      <td>36</td>\n      <td>117.64</td>\n      <td>75.00</td>\n      <td>90.00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>2</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>214.931</td>\n      <td>0</td>\n      <td>251</td>\n      <td>778486</td>\n      <td>7</td>\n      <td>183.91</td>\n      <td>98.00</td>\n      <td>104.12</td>\n      <td>2022</td>\n      <td>5</td>\n      <td>10</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>168.353</td>\n      <td>0</td>\n      <td>591</td>\n      <td>1870136</td>\n      <td>22</td>\n      <td>70.36</td>\n      <td>46.50</td>\n      <td>60.00</td>\n      <td>2023</td>\n      <td>4</td>\n      <td>15</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>40.860</td>\n      <td>1</td>\n      <td>325</td>\n      <td>1014639</td>\n      <td>21</td>\n      <td>145.66</td>\n      <td>159.74</td>\n      <td>200.00</td>\n      <td>2022</td>\n      <td>7</td>\n      <td>23</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>22.459</td>\n      <td>1</td>\n      <td>367</td>\n      <td>1149565</td>\n      <td>34</td>\n      <td>204.12</td>\n      <td>219.99</td>\n      <td>235.98</td>\n      <td>2022</td>\n      <td>9</td>\n      <td>3</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>37.480</td>\n      <td>1</td>\n      <td>341</td>\n      <td>1065697</td>\n      <td>65</td>\n      <td>382.92</td>\n      <td>184.00</td>\n      <td>207.00</td>\n      <td>2022</td>\n      <td>8</td>\n      <td>8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>10</td>\n      <td>1</td>\n      <td>3</td>\n      <td>832.065</td>\n      <td>1</td>\n      <td>80</td>\n      <td>240765</td>\n      <td>42</td>\n      <td>116.12</td>\n      <td>80.00</td>\n      <td>85.00</td>\n      <td>2021</td>\n      <td>11</td>\n      <td>20</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./formated_data/train.csv')\n",
    "df_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T10:04:35.695651Z",
     "start_time": "2023-12-20T10:04:35.622171700Z"
    }
   },
   "id": "53c361fa007fbf20"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "            county  is_business  product_type        target  is_consumption  \\\ncount  9959.000000  9959.000000   9959.000000   9959.000000     9959.000000   \nmean      7.297821     0.531479      1.901797    278.021151        0.493423   \nstd       4.789720     0.499033      1.079951    925.621791        0.499982   \nmin       0.000000     0.000000      0.000000      0.000000        0.000000   \n25%       3.000000     0.000000      1.000000      0.321000        0.000000   \n50%       7.000000     1.000000      2.000000     30.229000        0.000000   \n75%      11.000000     1.000000      3.000000    181.393000        1.000000   \nmax      15.000000     1.000000      3.000000  14689.333000        1.000000   \n\n       data_block_id        row_id  prediction_unit_id  euros_per_mwh  \\\ncount    9959.000000  9.959000e+03         9959.000000    9959.000000   \nmean      321.181143  1.006912e+06           33.072096     157.869716   \nstd       181.039567  5.776386e+05           19.647415     121.179830   \nmin         0.000000  1.810000e+02            0.000000     -10.060000   \n25%       166.000000  5.042945e+05           16.000000      86.340000   \n50%       322.000000  1.006775e+06           33.000000     130.010000   \n75%       476.000000  1.504046e+06           50.000000     199.970000   \nmax       635.000000  2.011820e+06           68.000000    4000.000000   \n\n       lowest_price_per_mwh  highest_price_per_mwh         year        month  \\\ncount           9959.000000            9959.000000  9959.000000  9959.000000   \nmean              95.730117             108.653294  2022.054222     6.441811   \nstd               47.066367              54.167743     0.640778     3.690448   \nmin               28.100000              34.000000  2021.000000     1.000000   \n25%               61.750000              67.760000  2022.000000     3.000000   \n50%               86.000000              94.000000  2022.000000     6.000000   \n75%              110.000000             133.000000  2022.000000    10.000000   \nmax              250.000000             305.000000  2023.000000    12.000000   \n\n               day         hour  \ncount  9959.000000  9959.000000  \nmean     15.604780    11.583593  \nstd       8.749616     6.911719  \nmin       1.000000     0.000000  \n25%       8.000000     6.000000  \n50%      16.000000    12.000000  \n75%      23.000000    18.000000  \nmax      31.000000    23.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>county</th>\n      <th>is_business</th>\n      <th>product_type</th>\n      <th>target</th>\n      <th>is_consumption</th>\n      <th>data_block_id</th>\n      <th>row_id</th>\n      <th>prediction_unit_id</th>\n      <th>euros_per_mwh</th>\n      <th>lowest_price_per_mwh</th>\n      <th>highest_price_per_mwh</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9.959000e+03</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n      <td>9959.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>7.297821</td>\n      <td>0.531479</td>\n      <td>1.901797</td>\n      <td>278.021151</td>\n      <td>0.493423</td>\n      <td>321.181143</td>\n      <td>1.006912e+06</td>\n      <td>33.072096</td>\n      <td>157.869716</td>\n      <td>95.730117</td>\n      <td>108.653294</td>\n      <td>2022.054222</td>\n      <td>6.441811</td>\n      <td>15.604780</td>\n      <td>11.583593</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.789720</td>\n      <td>0.499033</td>\n      <td>1.079951</td>\n      <td>925.621791</td>\n      <td>0.499982</td>\n      <td>181.039567</td>\n      <td>5.776386e+05</td>\n      <td>19.647415</td>\n      <td>121.179830</td>\n      <td>47.066367</td>\n      <td>54.167743</td>\n      <td>0.640778</td>\n      <td>3.690448</td>\n      <td>8.749616</td>\n      <td>6.911719</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.810000e+02</td>\n      <td>0.000000</td>\n      <td>-10.060000</td>\n      <td>28.100000</td>\n      <td>34.000000</td>\n      <td>2021.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.321000</td>\n      <td>0.000000</td>\n      <td>166.000000</td>\n      <td>5.042945e+05</td>\n      <td>16.000000</td>\n      <td>86.340000</td>\n      <td>61.750000</td>\n      <td>67.760000</td>\n      <td>2022.000000</td>\n      <td>3.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>30.229000</td>\n      <td>0.000000</td>\n      <td>322.000000</td>\n      <td>1.006775e+06</td>\n      <td>33.000000</td>\n      <td>130.010000</td>\n      <td>86.000000</td>\n      <td>94.000000</td>\n      <td>2022.000000</td>\n      <td>6.000000</td>\n      <td>16.000000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>11.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>181.393000</td>\n      <td>1.000000</td>\n      <td>476.000000</td>\n      <td>1.504046e+06</td>\n      <td>50.000000</td>\n      <td>199.970000</td>\n      <td>110.000000</td>\n      <td>133.000000</td>\n      <td>2022.000000</td>\n      <td>10.000000</td>\n      <td>23.000000</td>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>14689.333000</td>\n      <td>1.000000</td>\n      <td>635.000000</td>\n      <td>2.011820e+06</td>\n      <td>68.000000</td>\n      <td>4000.000000</td>\n      <td>250.000000</td>\n      <td>305.000000</td>\n      <td>2023.000000</td>\n      <td>12.000000</td>\n      <td>31.000000</td>\n      <td>23.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Drop \n",
    "df_train = df_train[df_train['target'].isna() == False]\n",
    "df_train = df_train[df_train['euros_per_mwh'].isna() == False]\n",
    "df_train = df_train[df_train['lowest_price_per_mwh'].isna() == False]\n",
    "df_train = df_train[df_train['highest_price_per_mwh'].isna() == False]\n",
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T10:04:35.739995700Z",
     "start_time": "2023-12-20T10:04:35.662552Z"
    }
   },
   "id": "38d6c5f16c102e1c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train - Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71c48ddf6b5c56d2"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_train.drop('target', axis=1)\n",
    "y = df_train['target']\n",
    "\n",
    "def spliting_dataset(test_ratio=0.2, random_state_nb=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=random_state_nb)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = spliting_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T10:34:43.145937800Z",
     "start_time": "2023-12-20T10:34:43.105526900Z"
    }
   },
   "id": "682b5c29c7730b0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelisation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfb9b85292256e4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "Creating a function to test all the errors on each model, just by calling this function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91a674861f481524"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, r2_score\n",
    "\n",
    "def getMAE(model, X_test, y_test):\n",
    "    mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "    return round(mae, 4)\n",
    "\n",
    "def model_evaluation(model_trained, test_evaluation=False):\n",
    "    if test_evaluation:\n",
    "        temp_y_pred = model_trained.predict(X_test)\n",
    "    else:\n",
    "        temp_y_pred = model_trained.predict(X_train)\n",
    "    \n",
    "    y_data = y_test if test_evaluation else y_train\n",
    "    \n",
    "    print(\"######## Test evaluation\") if test_evaluation else print(\"######## Train evaluation\")\n",
    "    print(f'R2 score: {round(r2_score(y_data, temp_y_pred), 4)} (aiming 1.0)')\n",
    "    print(f\"Mean absolute error : {round(mean_absolute_error(y_data, temp_y_pred), 4)} (aiming 0)\")\n",
    "    print(f\"Mean squared error : {round(mean_squared_error(y_data, temp_y_pred), 4)} (aiming 0)\")\n",
    "    # print(f\"Mean absolute percentage error : {mean_absolute_percentage_error(y_data, temp_y_pred)}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T10:47:41.197462700Z",
     "start_time": "2023-12-20T10:47:41.171529Z"
    }
   },
   "id": "cef528cbd5cfc1c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dummy\n",
    "Creating a dummy regressor to compare our model with this dummy one. \n",
    "And see if the actual model is worth using or no any better than a dummy one"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13c2317b9c1c9075"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Train evaluation\n",
      "R2 score: 0.0 (aiming 1.0)\n",
      "Mean absolute error : 363.0738 (aiming 0)\n",
      "Mean squared error : 803800.2244 (aiming 0)\n",
      "######## Test evaluation\n",
      "R2 score: -0.0004 (aiming 1.0)\n",
      "Mean absolute error : 382.708 (aiming 0)\n",
      "Mean squared error : 936167.1861 (aiming 0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "# Model training\n",
    "dummy = DummyRegressor().fit(X_train, y_train)\n",
    "better_dummy_mae = getMAE(dummy, X_test, y_test)\n",
    "\n",
    "# Evaluating model\n",
    "model_evaluation(dummy)\n",
    "model_evaluation(dummy, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T11:19:32.405748Z",
     "start_time": "2023-12-20T11:19:32.376827700Z"
    }
   },
   "id": "952b5b869092a048"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LinearRegression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "731f885cade9a6d9"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Train evaluation\n",
      "R2 score: 0.1282 (aiming 1.0)\n",
      "Mean absolute error : 361.6494 (aiming 0)\n",
      "Mean squared error : 700717.1737 (aiming 0)\n",
      "######## Test evaluation\n",
      "R2 score: 0.1193 (aiming 1.0)\n",
      "Mean absolute error : 380.7231 (aiming 0)\n",
      "Mean squared error : 824121.1177 (aiming 0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Model training\n",
    "better_reg_model = LinearRegression().fit(X_train, y_train)\n",
    "better_reg_mae = getMAE(better_reg_model, X_test, y_test)\n",
    "for i in range(1, 5):\n",
    "    X_train, X_test, y_train, y_test = spliting_dataset(test_ratio=i/10)\n",
    "    for j in range(1000):\n",
    "        reg = LinearRegression(n_jobs=j).fit(X_train, y_train)\n",
    "        \n",
    "        # Checking if the mean absolute error is better or not\n",
    "        tmp_mae = getMAE(reg, X_test, y_test)\n",
    "        if tmp_mae < better_mae:\n",
    "            better_mae = tmp_mae\n",
    "            better_reg_model = reg\n",
    "\n",
    "# Evaluating model\n",
    "model_evaluation(better_reg_model)\n",
    "model_evaluation(better_reg_model, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T10:56:06.926173800Z",
     "start_time": "2023-12-20T10:55:34.510345400Z"
    }
   },
   "id": "c5b30f951f9cd51a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lasso"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcf4cae58117ef25"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.133e+09, tolerance: 7.140e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.141e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.162e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.176e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.963e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e+09, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+06, tolerance: 7.140e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.851e+09, tolerance: 6.522e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.857e+09, tolerance: 6.522e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.391e+08, tolerance: 6.522e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+09, tolerance: 6.522e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.524e+09, tolerance: 5.781e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e+09, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.085e+09, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e+09, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e+09, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.503e+08, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e+09, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+08, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.566e+09, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e+09, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.553e+09, tolerance: 5.781e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+09, tolerance: 4.803e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.709e+08, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.140e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.498e+08, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.522e+08, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e+08, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+08, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Train evaluation\n",
      "R2 score: 0.012 (aiming 1.0)\n",
      "Mean absolute error : 359.874 (aiming 0)\n",
      "Mean squared error : 794187.1855 (aiming 0)\n",
      "######## Test evaluation\n",
      "R2 score: 0.0087 (aiming 1.0)\n",
      "Mean absolute error : 379.2963 (aiming 0)\n",
      "Mean squared error : 927680.2185 (aiming 0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Model training\n",
    "better_lasso_model = Lasso().fit(X_train, y_train)\n",
    "better_lasso_mae = getMAE(better_lasso_model, X_test, y_test)\n",
    "for i in range(1, 5):\n",
    "    X_train, X_test, y_train, y_test = spliting_dataset(test_ratio=i/10)\n",
    "    for j in range(1000):\n",
    "        reg = Lasso(alpha=j, selection=\"random\").fit(X_train, y_train)\n",
    "        \n",
    "        # Checking if the mean absolute error is better or not\n",
    "        tmp_mae = getMAE(reg, X_test, y_test)\n",
    "        if tmp_mae < better_mae:\n",
    "            better_lasso_mae = tmp_mae\n",
    "            better_lasso_model = reg\n",
    "\n",
    "# Evaluating model\n",
    "model_evaluation(better_lasso_model)\n",
    "model_evaluation(better_lasso_model, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T11:22:37.851142400Z",
     "start_time": "2023-12-20T11:22:12.537513Z"
    }
   },
   "id": "9b405a83d5e64f6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elastic Net"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f13cdf13e55e860"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\busin\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+09, tolerance: 4.803e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Train evaluation\n",
      "R2 score: 0.0124 (aiming 1.0)\n",
      "Mean absolute error : 359.871 (aiming 0)\n",
      "Mean squared error : 793843.0078 (aiming 0)\n",
      "######## Test evaluation\n",
      "R2 score: 0.0091 (aiming 1.0)\n",
      "Mean absolute error : 379.4305 (aiming 0)\n",
      "Mean squared error : 927252.6351 (aiming 0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Model training\n",
    "better_elastic_model = ElasticNet().fit(X_train, y_train)\n",
    "better_elastic_mae = getMAE(better_elastic_model, X_test, y_test)\n",
    "for i in range(1, 5):\n",
    "    X_train, X_test, y_train, y_test = spliting_dataset(test_ratio=i/10)\n",
    "    for j in range(1, 1000):\n",
    "        reg = ElasticNet(alpha=j, tol=1).fit(X_train, y_train)\n",
    "        \n",
    "        # Checking if the mean absolute error is better or not\n",
    "        tmp_mae = getMAE(reg, X_test, y_test)\n",
    "        if tmp_mae < better_mae:\n",
    "            better_elastic_mae = tmp_mae\n",
    "            better_elastic_model = reg\n",
    "\n",
    "# Evaluating model\n",
    "model_evaluation(better_elastic_model)\n",
    "model_evaluation(better_elastic_model, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:08:28.924521Z",
     "start_time": "2023-12-20T12:08:12.020035100Z"
    }
   },
   "id": "3d6ec332e9c1b469"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "860912428e2ce350"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[139], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m forest \u001B[38;5;241m=\u001B[39m RandomForestRegressor()\n\u001B[0;32m     13\u001B[0m RFR_random \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(estimator\u001B[38;5;241m=\u001B[39mforest, param_distributions\u001B[38;5;241m=\u001B[39mgrid_param, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m \u001B[43mRFR_random\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m better_rdm_forest_mae \u001B[38;5;241m=\u001B[39m getMAE(RFR_random, X_test, y_test)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Evaluating model\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    894\u001B[0m     )\n\u001B[0;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1807\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1808\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1809\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1810\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1811\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m   1812\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1813\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    838\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    839\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    841\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    842\u001B[0m         )\n\u001B[0;32m    843\u001B[0m     )\n\u001B[1;32m--> 845\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    865\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    866\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    867\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\dev\\python\\enefit_data_pycharm\\.venv\\lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Hyperparameters\n",
    "grid_param = {'n_estimators': [500, 800, 1500, 2500, 5000], \n",
    "              'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "              'max_depth': [10, 20, 30, 40, 50], \n",
    "              'min_samples_split': [2, 5, 10, 15, 20], \n",
    "              'min_samples_leaf':[1, 2, 5, 10, 15]}\n",
    "\n",
    "# Model training\n",
    "forest = RandomForestRegressor()\n",
    "RFR_random = RandomizedSearchCV(estimator=forest, param_distributions=grid_param, n_iter=500, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "RFR_random.fit(X_train, y_train)\n",
    "better_rdm_forest_mae = getMAE(RFR_random, X_test, y_test)\n",
    "# Evaluating model\n",
    "model_evaluation(forest)\n",
    "model_evaluation(forest, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:30:34.794152900Z",
     "start_time": "2023-12-20T12:19:30.059937700Z"
    }
   },
   "id": "6910a9943324f5d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Xgboost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93a19d08ce83c66c"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Train evaluation\n",
      "R2 score: 0.9917 (aiming 1.0)\n",
      "Mean absolute error : 49.1518 (aiming 0)\n",
      "Mean squared error : 6692.6493 (aiming 0)\n",
      "######## Test evaluation\n",
      "R2 score: 0.8641 (aiming 1.0)\n",
      "Mean absolute error : 146.768 (aiming 0)\n",
      "Mean squared error : 127154.1872 (aiming 0)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "bst = XGBRegressor().fit(X_train, y_train)\n",
    "better_xgb_mae = getMAE(bst, X_test, y_test)\n",
    "\n",
    "model_evaluation(bst)\n",
    "model_evaluation(bst, True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T11:21:44.895425Z",
     "start_time": "2023-12-20T11:21:44.714718Z"
    }
   },
   "id": "114327eb482072f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c77d166f806f2072"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model       MAE\n",
      "0             Dummy  382.7080\n",
      "1  LinearRegression  380.7231\n",
      "2             Lasso  379.2963\n",
      "3       Elastic Net  379.4305\n",
      "4      RandomForest  116.0695\n",
      "5           XGBoost  146.7680\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Creating a temporary dataframe for MAE errors\n",
    "d = {\"Model\" : [\"Dummy\", \"LinearRegression\", \"Lasso\", \"Elastic Net\",\"RandomForest\", \"XGBoost\"],\n",
    "     \"MAE\" : [better_dummy_mae, better_reg_mae, better_lasso_mae, better_elastic_mae, better_rdm_forest_mae, better_xgb_mae]}\n",
    "mae_array = pd.DataFrame(data=d, columns=[\"Model\", \"MAE\"])\n",
    "print(mae_array)\n",
    "\n",
    "# Creating the graph\n",
    "ax = sns.barplot(mae_array, x=\"Model\", y=\"MAE\")\n",
    "ax.bar_label(ax.containers[0], fontsize=10);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:09:30.534027Z",
     "start_time": "2023-12-20T12:09:30.348806400Z"
    }
   },
   "id": "2da364ebb94ca641"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aa2471ebb25be458"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
